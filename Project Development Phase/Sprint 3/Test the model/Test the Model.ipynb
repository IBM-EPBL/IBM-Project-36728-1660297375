{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bvPFFjo_AYn-"
      },
      "outputs": [],
      "source": [
        "#Importing Libarries\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the model\n",
        "\n",
        "model = load_model('aslpng1.h5')"
      ],
      "metadata": {
        "id": "WczOsxz1BSCh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.transform import resize\n",
        "def detect(frame):\n",
        "    img = resize(frame, (64, 64, 3))\n",
        "    img = np.expand_dims(img, axis = 0)\n",
        "    if np.max(img) > 1:\n",
        "        img = img/255.0\n",
        "    prediction = model.predict(img)\n",
        "    print(prediction)\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "dFYal_HIBXp1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame = cv2.imread(r\"/content/data.zip/Dataset/training_set/D/1011.png\")\n",
        "data = detect(frame)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPDrsIsGBcV9",
        "outputId": "0a5d8a0e-2a0f-4988-e828-4cc953c4e5d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 315ms/step\n",
            "[[4.7686200e-07 2.0770119e-06 4.1236445e-10 9.9997914e-01 4.2484130e-06\n",
            "  1.0205887e-05 4.5596771e-08 2.0244920e-07 3.6153117e-06]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = ['A','B','C','D','E','F','G','H','I']\n",
        "index[np.argmax(data)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6USQYUeXBgBG",
        "outputId": "60d9622a-25a7-477d-d5b0-f5edf3b397a9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenCV"
      ],
      "metadata": {
        "id": "VwFM2sVPBjkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Library\n",
        "\n",
        "import cv2"
      ],
      "metadata": {
        "id": "IMXub4ZQBpse"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img=cv2.imread(r'/content/data.zip/Dataset/training_set/C/10.png',1)"
      ],
      "metadata": {
        "id": "D9jmsDHSOUOR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1=cv2.imread(r'/content/data.zip/Dataset/training_set/D/10.png',0)"
      ],
      "metadata": {
        "id": "3ZP-ReKaOpN9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHw-gfWaO0Qn",
        "outputId": "2d75c224-ada4-4232-f6a6-0f7b716fd1e5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing library\n",
        "\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "1s80oI3VPgaL"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "wdGNbtZvPtQ8",
        "outputId": "1f4a2252-f4c8-4b9f-c709-3c7a02dd8cbd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F1BA03FD910>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAC5UlEQVR4nO2aPc8pQRTHZy8KCUFoFESp0mgUEpVEpxO+wEOj0QgaiYiPQCXRiG+g0Ep8BDTipdiGbCQSEsXcYnP3in15ZnbOGMX+KtbuOf8/Z86e3YWQg4ODg4ODgzgk9hAY47cts9lMfVGpVNjj8wUTs1qtRIvVQa5e43w+i1b9j/1+b8OAymAwEKZblmXbujVutxuUHrpFjDH2er33+x0mtwTQQv6Q77rf7xFCUOoRQtVqlT0IhYFEIoF1HZOFQCAAGI2Ut2q+Xq/q9vV6bW89CPCwWq0smrqiKN9u4FeoPBQKBZZcFGuAnM1mwyOsIQCNzBCq2mDpp1x+AVpYVgIvAz8/P1T7h8NhTkrsQ9WLksmkaL06isUilQfReo2gMhAKhWyk4NWFVGx8r7Qd6Su6kIbX66U95LsMqAMvFV9XQoiyitwWn3k8HpfLhRB6PB42dAjG7/ez92mqLqQhyzJ5CtM10G63X9+q4z6Veiodr1BdMVtVm6Fi8gJlOTeRZ7HqQqPRSL8xn8+TxD0ej4QKDFmv1yyH/+dwONg759urfo1GowFjwEyKdX3vdjtGA7bXjwHz+dwszXa71e9fKpUY1atA3kv9NZl2q3AwGICoxxhPJhMSbUSLHQuadU+nUzwet97nu2ahN9xuq0FBhciAJEmn04lZDzXRaDSXy4GFS6fTUPVNBZgBlVQq9WEDw+EQ2ANCKJvNftJDp9MxU2JzES+XS3XS/gw+n8/sIy5PKXlgNt4BtFFJkur1Onsca5rNpnF2wByKogSDQcCAbxj+CJAnslAodLlcAAOSAHwmjkQi/X4fNqbKeDyOxWI8IhvQ6/V4NNNyufwhAwihbrfLw4M+Ed/7Qs/nk2QgI0e/jvlOox6Pp9VqAQacTqeA0Sio1WogJbRYLMQYUIlGo+we3p5qfvSCRpZl9v9HZLPZ17d8F7EZmG18ev0WxFxSRiIRlsMzmYz2WowBwIlDTAkhuCr6C57V4fcKkkDbAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN Video Analysis"
      ],
      "metadata": {
        "id": "vb3uVKk_PB4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "model=load_model('aslpng1.h5')\n",
        "video=cv2.VideoCapture(0)\n",
        "index=['A','B','C','D','E','F','G','H','I']\n",
        "if video.isOpened():\n",
        "    current_frame = 0\n",
        "    while 1:\n",
        "      succes,frame=video.read()\n",
        "      cv2.imwrite('image.jpg',frame)\n",
        "      img=image.load_img('image.jpg',target_size=(64,64))\n",
        "      x=image.img_to_array(img)\n",
        "      x=np.expand_dims(x,axis=0)\n",
        "      pred=np.argmax(model.predict(x),axis=1)\n",
        "      y=pred[0]\n",
        "      copy = frame.copy()\n",
        "      cv2.rectangle(copy, (320, 100), (620,400), (255,0,0), 5)\n",
        "      cv2.putText(frame,'The Predicted Alphabet is: '+str(index[y]),(100,100),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,0),4)\n",
        "      cv2.imshow('image',frame)\n",
        "      if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "          break\n",
        "video.release()\n",
        "cv2.destroyAllWindows()  "
      ],
      "metadata": {
        "id": "pPSeJlwnPK1r"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}